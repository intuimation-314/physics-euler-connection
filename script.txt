\documentclass{article}
\usepackage{amsmath, amssymb}

\title{This Classic Physics Problem's Beautiful Connection to Euler’s Formula Totally Blew Me Away}
\author{}
\date{}

\begin{document}

\maketitle

\section*{Introduction to the Problem}

Imagine a block on a frictionless surface being pulled in one direction. According to Newton's laws, the block accelerates in that direction. But what happens if you apply an equal force in the opposite direction? The forces cancel out, and the block stays still. In this case, the block is in equilibrium. The two forces acting on it form an angle of \( \frac{2\pi}{2} \), which is \( \pi \) radians or 180 degrees, dividing the circle into two equal parts.

Now, let’s take it a step further. What if we have three forces? How can we achieve equilibrium with these three forces acting on the block? To do this, we arrange each force such that these three forces divide the circle into 3 equal parts, meaning each force makes an angle of \( \frac{2\pi}{3} \) radians. Let’s verify this arrangement by adding the vectors. We can use the \textbf{parallelogram law of vector addition}: when two vectors are adjacent sides of a parallelogram, the resultant vector is represented by the diagonal. By extending this principle to three forces, we can see that the sum of the first two forces creates a resultant force. The third force will exactly cancel out this resultant, putting the block in equilibrium.

Next, let’s consider the case with four forces. If the forces are evenly spaced, each force will make an angle of \( \frac{\pi}{2} \) radians (90 degrees) with the next. Each force has an opposite counterpart, which cancels out the other. So, just like in the previous cases, the system is in equilibrium.

This idea works for any number of forces—whether it's 5, 6, or 7 forces—so long as they’re evenly spaced around a circle and greater than one. if there’s only one force, there’s no balancing force to cancel it out, and equilibrium cannot be achieved.

Here is a problem I want to address: Picture this: you have \( n \) vectors grater than one, all of the same magnitude, spreading out from a central point and evenly spaced around a circle. Each one makes an angle of \( \frac{2\pi}{n} \) radians with the next. The big question is: what’s the resultant sum of all these vectors?

So far we know these vectors perfectly cancel each other out, resulting in a sum of zero. But why these forces cancel out? Many text book explanation simply says its "symmetry." But just saying "symmetry" doesn't really give us a full explanation of why the sum is zero. One way to get a better grasp of this is by picturing the vectors being shifted, without changing their angles, so that the tail of one connects to the head of another. When you do this, they form a closed polygon, which is why the resultant sum is zero. It’s a cool way to visualize the concept. But Mathematicians are not quite convinced with these type of visual explanations.

The goal of this video is to provide the mathematical proof behind this phenomenon. There is a beautiful and elegant proof offered by the beautiful theorem Euler’s formula that you might not encounter in typical textbooks.

It might seem surprising that such an abstract concept like Euler’s Formula can prove something so practical in physics, but trust me, this video is going to be exciting. We’re about to explore one of the most beautiful connections between math and physics.

I'll start with how I first encountered this problem in my high school physics class.

\section*{Example encountered in Physics}

Picture a ring with a uniform positive charge. What’s the electric field intensity at its center?

Think of this ring as being made up of many infinitesimal charge elements \( dQ \). Each element creates a small electric field \( dE \), which is directed radially outward along the line connecting \( dQ \) and the center of the ring. According to Coulomb's law, the magnitude of this electric field is given by:

\[
|dE| = \frac{k_e \cdot |dQ|}{r^2}
\]

where \( k_e \) is Coulomb's constant, \( |dQ| \) is the magnitude of the charge element, and \( r \) is the distance from the charge to the point where the field is being calculated—in this case, the center of the ring.

The magnitude of the electric field depends on the amount of charge \( dQ \) and the distance \( r \) from the charge. Since we are considering a uniformly charged ring, each element \( dQ \) has the same charge because the charge is evenly distributed along the entire ring. Additionally, because all these elements are equidistant from the center, being part of a circle, the electric fields they produce are of equal magnitude.

The vector sum of all these electric fields turns out to be zero.

When I asked my teacher why this happens, he simply said, "It's symmetry." Each charge element \( dQ \) on the ring has an equal \( dQ \) located directly opposite, canceling each other out. This symmetry explanation works well for continuous charge distributions. But what happens if we’re dealing with a discrete number of charges around the circle?

With an even number of charges, it’s easy to see that each electric field has an exact opposite to cancel it out. But what if there’s an odd number of charges? There’s no exact opposite field to cancel out each one. So, does this balancing act still hold for any number of vectors?

\section*{Proof: Discrete Case}

Let’s start by considering these vectors at the origin of an \( x \)-\( y \) plane. To keep things simple, we'll assume that each vector has a magnitude of 1.

Let's assign numbers to these vectors from \( 0 \) to \( n-1 \). We'll assume \( k \) represents the index of each vector, ranging from \( 0 \) to \( n-1 \). For each vector \( k \), we can describe its components using unit vectors along the \( x \)-axis and \( y \)-axis. Here, the \( x \)-component represents the projection of the vector along the \( x \)-axis, scaled by the cosine of the angle it makes with the \( x \)-axis \( \theta_k \): 

\[
\text{x-component} = \cos\left(\theta_k\right) \hat{i}
\]

Similarly, the \( y \)-component represents the projection along the \( y \)-axis, scaled by the sine of the angle:

\[
\text{y-component} = \sin\left(\theta_k\right) \hat{j}
\]

Here, the angle \(\theta_k\) can be expressed as a function of the vector index \(k\), for each vector. Since each vector is evenly spaced around a circle, the angle between consecutive vectors is \(\frac{2\pi}{n}\):

The 0th vector aligns with the x-axis, making an angle of \(0\) radians.  
The 1st vector makes an angle of \(\frac{2\pi}{n}\) radians with the x-axis.  
The 2nd vector makes an angle of \(\frac{2\cdot2\pi}{n}\) radians with the x-axis.  
The 3rd vector makes an angle of \(\frac{2\cdot3\pi}{n}\) radians with the x-axis.

Following this pattern, the \(k\)-th vector makes an angle of \(\frac{2k\pi}{n}\) radians with the x-axis.

Substituting this expression for \(\theta_k\) into our vector expression, we get:

\[
\vec{\text{v}}_k = \cos\left(\frac{2k\pi}{n}\right) \hat{i} + \sin\left(\frac{2k\pi}{n}\right) \hat{j}
\]

The \(k\)-th vector, represented by \(v_k\), can thus be written as the sum of these components:

\[
\vec{\text{v}}_k = \cos\left(\theta_k\right) \hat{i} + \sin\left(\theta_k\right) \hat{j}
\]

Now, to find the total vector sum, we add up all the vectors from \(k = 0\) to \(n - 1\). The total vector sum is:

\[
\sum_{k=0}^{n-1} \vec{\text{v}}_k = \sum_{k=0}^{n-1} \left(\cos\left(\frac{2k\pi}{n}\right) \hat{i} + 
\sin\left(\frac{2k\pi}{n}\right) \hat{j}\right)
\]

Breaking this down into x and y components, we have:

\[
\sum_{k=0}^{n-1} \cos\left(\frac{2k\pi}{n}\right) \hat{i} + \sum_{k=0}^{n-1} \sin\left(\frac{2k\pi}{n}\right) \hat{j}
\]

Thus, the sum of all the vectors is the sum of the x-components plus the sum of the y-components. This decomposition simplifies the process of finding the resultant vector.

To prove that the vector sum is zero, we need to show that both the sum of the x and y components sum to zero simultaneously. That is, we need to prove:

\[
\sum_{k=0}^{n-1} \cos\left(\frac{2k\pi}{n}\right) = 0 \quad \text{and} \quad \sum_{k=0}^{n-1} 
\sin\left(\frac{2k\pi}{n}\right) = 0
\]

This is a crucial sub-problem within the broader problem we're addressing. But how do we prove that these sums are zero at the same time? In a typical math class, you might encounter this kind of problem to solve. If we just look at it, it may seem abstract, and one might ask, "Why is this useful?"

What I love about physics is that it shows you where the problem actually originates from. In this case, solving this can be incredibly useful, especially when it comes to understanding the sum of vectors. While there might be some trigonometric methods to prove this, they would likely be complex and tedious. This is where Euler's formula comes in. It simplifies the process and provides a beautiful proof, which is the key point I want to focus on in my video today.

If you clicked on this video, you probably already have a basic understanding of Euler's Formula. I won’t dive deep into the details since I’ve covered it in my earlier videos in this playlist. For now, let me give you a quick overview. Picture a point in a complex plane that is a unit distance away from the origin making an angle \(\theta\) with the x-axis. It represents a complex number with real part \(\cos(\theta)\) and imaginary part \(\sin(\theta)\). According to Euler's Formula, this complex number can also be written in an exponential form:

\[
e^{i\theta} = \cos(\theta) + i\sin(\theta)
\]

In this context, we are going to shift these vectors into the complex plane. Here each vector can be represented as a complex number, where the real part \(\cos\left(\frac{2k\pi}{n}\right)\) corresponds to the x-component and the imaginary part \(\sin\left(\frac{2k\pi}{n}\right)\) corresponds to the y-component. Thanks to Euler's Formula, these vectors can also be written in an exponential form:

\[
e^{i\frac{2k\pi}{n}} = \cos\left(\frac{2k\pi}{n}\right) + i\sin\left(\frac{2k\pi}{n}\right)
\]

So, the sum of all these vectors is:

\[
\sum_{k=0}^{n-1} e^{i\frac{2k\pi}{n}} = \sum_{k=0}^{n-1} \cos\left(\frac{2k\pi}{n}\right) + 
i\sum_{k=0}^{n-1} \sin\left(\frac{2k\pi}{n}\right)
\]

If we can somehow prove that the sum of these exponents is zero, i.e.,

\[
\sum_{k=0}^{n-1} e^{i\frac{2k\pi}{n}} = 0
\]

then both its real and imaginary parts must also be zero. This would imply:

\[
\sum_{k=0}^{n-1} \cos\left(\frac{2k\pi}{n}\right) = 0 \quad \text{and} \quad \sum_{k=0}^{n-1} 
\sin\left(\frac{2k\pi}{n}\right) = 0
\]

The sum of x and y components of the vectors is zero, resulting in a null or zero vector.

Alright, let’s jump right into our final proof. Let’s take another look at this exponential representation of the vector sum:

\[
\sum_{k=0}^{n-1} e^{i\frac{2k\pi}{n}}
\]

When we expand this summation, it looks like this:

\[
\sum_{k=0}^{n-1} e^{i\frac{2k\pi}{n}} = 1 + e^{i \frac{2\pi}{n}} + e^{i \frac{4\pi}{n}} + \ldots + 
e^{i \frac{2(n-1)\pi}{n}}
\]

Notice that \( e^{i \frac{2\pi}{n}} \) is common in all terms, so let’s make things simpler by setting \(e^{i \frac{2\pi}{n}} = x\). Now, our series looks like this:

\[
1 + x + x^2 + x^3 + \ldots + x^{n-1}
\]

This should look familiar—it’s a geometric series! To sum up a geometric series, we use a specific formula. The sum of this geometric series is given by:

\[
\frac{1-x^n}{1-x}
\]

Since we have \( x = e^{i \frac{2\pi}{n}} \), replacing \( x \) in the formula, we get:
\[
\frac{1 - e^{i\frac{2\pi}{n} \cdot n}}{1 - e^{i\frac{2\pi}{n}}}
\]

Here, the two \( n \) terms in the exponent cancel out, leaving us with:

\[
\frac{1 - e^{i2\pi}}{1 - e^{i\frac{2\pi}{n}}}
\]

Now, from Euler's formula, we know:

\[
e^{i 2\pi} = \cos(2\pi) + i\sin(2\pi)
\]

which simplifies to 1. So, the sum becomes:

\[
\frac{1 - 1}{1 - e^{i\frac{2\pi}{n}}} = 0
\]

Since the numerator is 0, the whole expression equals 0 regardless of the denominator. Therefore, the total sum is 0.

Remember, we initially considered unit vectors. However, this result holds true for vectors of any magnitude. We can set aside this result for unit vectors for now.

Suppose the vectors have a magnitude of \( r \), geometrically it means all these unit vectors are scaled by a factor of \( r \). When you look at Euler's expression for these vectors, this is what it looks like:

\[
\sum_{k=0}^{n-1} r \cdot e^{i\frac{2k\pi}{n}}
\]

Since \( r \) is constant, we can pull it out of the summation:

\[
r \cdot \sum_{k=0}^{n-1} e^{i\frac{2k\pi}{n}}
\]

We already proved what this summation is: 0

Hence, \( r \cdot 0 = 0 \).

And that wraps up our proof that the sum of the vectors is zero, using Euler's formula and the properties of geometric series.

\section*{Continuous Case}


The beauty of this problem is that it isn't limited to just a finite number of vectors. We can use the same principle to prove that the sum is zero even for continuous charge distributions or any continuous distribution of forces—just like the charged ring example we saw earlier.

When we move from a discrete set of vectors to a continuous distribution, the summation transits into an integral. 

The summation:

\[
\sum_{k=0}^{n-1} e^{i\frac{2k\pi}{n}}
\]

can be transformed into an integral as \( n \to \infty \):

\[
\lim_{n \to \infty} \sum_{k=0}^{n-1} e^{i\frac{2k\pi}{n}}
= \frac{n}{2\pi} \int_0^{2\pi} e^{i\theta} \, d\theta.
\]

To evaluate the integral, use the antiderivative of \( e^{i\theta} \):

\[
\int e^{i\theta} \, d\theta = \frac{e^{i\theta}}{i}.
\]

Substituting the limits:

\[
\int_0^{2\pi} e^{i\theta} \, d\theta = \left[\frac{e^{i\theta}}{i}\right]_0^{2\pi}.
\]

At \( \theta = 2\pi \):

\[
e^{i\theta} = e^{i2\pi} = 1.
\]

At \( \theta = 0 \):

\[
e^{i\theta} = 1.
\]

Thus:

\[
\int_0^{2\pi} e^{i\theta} \, d\theta = \frac{1 - 1}{i} = 0.
\]

Hence, the integral of \( e^{i\theta} \) from 0 to \( 2\pi \) is zero.

This proves that the sum of vectors is zero even in a continuous distribution, just like in the discrete case.

\section*{Verifying Result Computationally}

For my programming friends who might not prefer this detailed proof, or for anyone looking to verify the result computationally, here’s a Python code snippet you can use to confirm the outcome.

\begin{verbatim}
import numpy as np

def vector_sum(n):
    # Initialize x and y components to 0
    x_component, y_component = 0, 0
    
    # Sum up the x and y components of all vectors
    for k in range(n):
        angle = 2 * k * np.pi / n  # Calculate angle for each vector
        x_component += np.cos(angle)  # Sum x components
        y_component += np.sin(angle)  # Sum y components
    
    # Return the rounded resultant vector sum (x, y components)
    return round(x_component, 2), round(y_component, 2)

# Example with 12 vectors (you can change n to test different values)
n = 12
result = vector_sum(n)
print(f"Resultant vector sum: ({result[0]}, {result[1]})")

# Expected output should be close to (0, 0) for any n > 1

\end{verbatim}

The code calculates the sum of \( n \) unit vectors evenly spaced around a circle. By setting `n = 12`, you should see the result as nearly (0, 0), confirming that the vectors balance out as expected. You can change `n` to any positive integer greater than 1 to explore the effect of different numbers of vectors.

The cool thing about this problem is how simple it seems at first, yet the solution has so much depth. What starts off as a basic vector addition puzzle turns into an exciting dive into complex numbers and geometric series.

\section*{Applications}

This really shows how abstract math concepts can give us such clear and elegant solutions to real-world problems.

But the examples we explored earlier are just a glimpse into the many applications of this concept.

\begin{itemize}
    \item For instance, in 2D molecular geometry, consider benzene \((C_6H_6)\). This molecule is planar, with carbon atoms arranged in a perfect hexagon. The bond vectors between the carbon atoms cancel each other out due to their symmetrical arrangement, which contributes to the stability of benzene. This is a great example of how symmetry in vector addition plays a crucial role in real-world chemistry.
    
    \item Another interesting application is in three-phase power systems. In a balanced three-phase system, the three alternating currents are spaced 120 degrees apart, and their vector sum is zero. This balance is crucial for the efficient transmission of electrical power, preventing unwanted vibrations or energy losses, which is why three-phase power systems are the standard in industrial and commercial power distribution.
    
    \item And lastly, let’s not forget rotational systems like fans and turbines. The forces exerted by the blades of a fan are designed to cancel out, allowing for smooth, balanced rotation without any wobbling or unnecessary wear and tear.
\end{itemize}

Whether you’re here out of curiosity or to dig deeper, I hope you enjoyed this journey as much as I did. If you liked this video, make sure to hit that thumbs up and subscribe to Intuimation for more awesome math adventures.


Thanks for watching, and until next time, keep exploring the amazing world of math!

\end{document}